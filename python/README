#########Section 1 Preprocess the data for model training####
## go to clustdell, and run the following cmd. It would submit the jobs to clustdell.
sh s_run_whole_pipeline_qsub.sh 358samples_regionkeepLow

#Overview of the preprocess:
Step 1. Get the location of each gene, including the gene start position, end position.
Step 2. Define the gene promoter regions, which is the 2kb around the gene start position and the overlapped hic-fragments. 
Step 3. For each gene, identify the distal regulatory regions which interact with the gene promoter regions in HiC data.
Step 4. Callculate the impact of individual variants on TF binding based on DeepSEA.
Step 5. For each gene, identify the set of altered TF binding events within the promoter and distal regulatory regions.
Step 6. Create the model training data for each gene, the format of training data:
chr, feature_start, feature_end, type, hic_id, 358 columns(each column is the feature alteration score of each individual)
Step 7. Do the model training for each gene.
Step 8. Downstream analysis for model performance, selected features. 



###########Section 2 Calculate the variation impact using deepsea###############

##subset the 1000 genome variants into the ENCODE TF binding regions.
##Get the genotype of each training sample.Then split vcf file for each sample.
p_extract_sample_vcf_file_in_regions.py


##Get a unique set of variants in the training samples. Merged the individuals vcfs into single non-redundant one for the input of DeepSEA to save time.
##The merged file would be different from the previous step. Now each line is only for one genotype and multiple lines for the same loci. 
##The previous one just put genotypes of all the individuals in one line.
p_deepsea_merge_individual_vcfs.py: 


##Run the deepsea for each chromosome
./deepsea/p_batch_run_deepsea.py

##Get the DeepSEA alteration score for each individual
./R/s_deepsea_split_impact_to_individuals.R: split the deepsea impact into each individuals.



